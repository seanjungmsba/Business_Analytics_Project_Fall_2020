{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.0 0.0003353501304664781\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################### Visualization of Sigmoid Function ####################################\n",
    "\n",
    "# Import necessary libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# List of values\n",
    "z = np.arange(-8, 8, 0.1) # Return evenly spaced values within a given interval using the specified step \n",
    "phi_z = sigmoid(z)        # Takes z as input and returns sigmoid of z\n",
    "print(z[0],phi_z[0])      # See first elements of arrays\n",
    "\n",
    "# Visualization parameters\n",
    "plt.plot(z, phi_z)          # Specify what to plot\n",
    "plt.axvline(0.0, color='k') # Add a vertical line across the axes\n",
    "plt.ylim(-0.1, 1.1)         # Set the y-limits of the current axes\n",
    "plt.xlabel('z')             # Set label of x axis         \n",
    "plt.ylabel('$\\phi (z)$')    # Set label of y axis\n",
    "\n",
    "# y axis ticks and gridline\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "ax = plt.gca()\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area.\n",
    "plt.show()         # Display the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID number</th>\n",
       "      <th>radius (mean)</th>\n",
       "      <th>texture (mean)</th>\n",
       "      <th>perimeter (mean)</th>\n",
       "      <th>area (mean)</th>\n",
       "      <th>smoothness (mean)</th>\n",
       "      <th>compactness (mean)</th>\n",
       "      <th>concavity (mean)</th>\n",
       "      <th>concave points (mean)</th>\n",
       "      <th>symmetry (mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>radius (largest)</th>\n",
       "      <th>texture (largest)</th>\n",
       "      <th>perimeter (largest)</th>\n",
       "      <th>area (largest)</th>\n",
       "      <th>smoothness (largest)</th>\n",
       "      <th>compactness (largest)</th>\n",
       "      <th>concavity (largest)</th>\n",
       "      <th>concave points (largest)</th>\n",
       "      <th>symmetry (largest)</th>\n",
       "      <th>fractal dimension (largest)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID number  radius (mean)  texture (mean)  perimeter (mean)  \\\n",
       "count  5.690000e+02     569.000000      569.000000        569.000000   \n",
       "mean   3.037183e+07      14.127292       19.289649         91.969033   \n",
       "std    1.250206e+08       3.524049        4.301036         24.298981   \n",
       "min    8.670000e+03       6.981000        9.710000         43.790000   \n",
       "25%    8.692180e+05      11.700000       16.170000         75.170000   \n",
       "50%    9.060240e+05      13.370000       18.840000         86.240000   \n",
       "75%    8.813129e+06      15.780000       21.800000        104.100000   \n",
       "max    9.113205e+08      28.110000       39.280000        188.500000   \n",
       "\n",
       "       area (mean)  smoothness (mean)  compactness (mean)  concavity (mean)  \\\n",
       "count   569.000000         569.000000          569.000000        569.000000   \n",
       "mean    654.889104           0.096360            0.104341          0.088799   \n",
       "std     351.914129           0.014064            0.052813          0.079720   \n",
       "min     143.500000           0.052630            0.019380          0.000000   \n",
       "25%     420.300000           0.086370            0.064920          0.029560   \n",
       "50%     551.100000           0.095870            0.092630          0.061540   \n",
       "75%     782.700000           0.105300            0.130400          0.130700   \n",
       "max    2501.000000           0.163400            0.345400          0.426800   \n",
       "\n",
       "       concave points (mean)  symmetry (mean)  ...  radius (largest)  \\\n",
       "count             569.000000       569.000000  ...        569.000000   \n",
       "mean                0.048919         0.181162  ...         16.269190   \n",
       "std                 0.038803         0.027414  ...          4.833242   \n",
       "min                 0.000000         0.106000  ...          7.930000   \n",
       "25%                 0.020310         0.161900  ...         13.010000   \n",
       "50%                 0.033500         0.179200  ...         14.970000   \n",
       "75%                 0.074000         0.195700  ...         18.790000   \n",
       "max                 0.201200         0.304000  ...         36.040000   \n",
       "\n",
       "       texture (largest)  perimeter (largest)  area (largest)  \\\n",
       "count         569.000000           569.000000      569.000000   \n",
       "mean           25.677223           107.261213      880.583128   \n",
       "std             6.146258            33.602542      569.356993   \n",
       "min            12.020000            50.410000      185.200000   \n",
       "25%            21.080000            84.110000      515.300000   \n",
       "50%            25.410000            97.660000      686.500000   \n",
       "75%            29.720000           125.400000     1084.000000   \n",
       "max            49.540000           251.200000     4254.000000   \n",
       "\n",
       "       smoothness (largest)  compactness (largest)  concavity (largest)  \\\n",
       "count            569.000000             569.000000           569.000000   \n",
       "mean               0.132369               0.254265             0.272188   \n",
       "std                0.022832               0.157336             0.208624   \n",
       "min                0.071170               0.027290             0.000000   \n",
       "25%                0.116600               0.147200             0.114500   \n",
       "50%                0.131300               0.211900             0.226700   \n",
       "75%                0.146000               0.339100             0.382900   \n",
       "max                0.222600               1.058000             1.252000   \n",
       "\n",
       "       concave points (largest)  symmetry (largest)  \\\n",
       "count                569.000000          569.000000   \n",
       "mean                   0.114606            0.290076   \n",
       "std                    0.065732            0.061867   \n",
       "min                    0.000000            0.156500   \n",
       "25%                    0.064930            0.250400   \n",
       "50%                    0.099930            0.282200   \n",
       "75%                    0.161400            0.317900   \n",
       "max                    0.291000            0.663800   \n",
       "\n",
       "       fractal dimension (largest)  \n",
       "count                   569.000000  \n",
       "mean                      0.083946  \n",
       "std                       0.018061  \n",
       "min                       0.055040  \n",
       "25%                       0.071460  \n",
       "50%                       0.080040  \n",
       "75%                       0.092080  \n",
       "max                       0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import urlopen package to read files directly from the websites\n",
    "from urllib.request import urlopen\n",
    "\n",
    "link = \"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "f = urlopen(link)\n",
    "data = f.read()\n",
    "\n",
    "feature_name = [\"ID number\", \"Diagnosis\", \"radius (mean)\", \"texture (mean)\", \"perimeter (mean)\", \"area (mean)\", \"smoothness (mean)\", \"compactness (mean)\", \"concavity (mean)\", \"concave points (mean)\", \"symmetry (mean)\", \"fractal dimension (mean)\", \"radius (std)\", \"texture (std)\", \"perimeter (std)\", \"area (std)\", \"smoothness (std)\", \"compactness (std)\", \"concavity (std)\", \"concave points (std)\", \"symmetry (std)\", \"fractal dimension (std)\", \"radius (largest)\", \"texture (largest)\", \"perimeter (largest)\", \"area (largest)\", \"smoothness (largest)\", \"compactness (largest)\", \"concavity (largest)\", \"concave points (largest)\", \"symmetry (largest)\", \"fractal dimension (largest)\"]\n",
    "feature_name\n",
    "\n",
    "# Converting bytes to Pandas dataframe\n",
    "# Code adpated from: https://stackoverflow.com/questions/47379476/how-to-convert-bytes-data-into-a-python-pandas-dataframe\n",
    "from io import StringIO\n",
    "s=str(data,'utf-8')\n",
    "data = StringIO(s) \n",
    "df=pd.read_csv(data, header=None)\n",
    "df.columns = feature_name\n",
    "\n",
    "# Change the column types\n",
    "df[[\"radius (mean)\", \"texture (mean)\", \"perimeter (mean)\", \"area (mean)\", \"smoothness (mean)\", \"compactness (mean)\", \"concavity (mean)\", \"concave points (mean)\", \"symmetry (mean)\", \"fractal dimension (mean)\", \"radius (std)\", \"texture (std)\", \"perimeter (std)\", \"area (std)\", \"smoothness (std)\", \"compactness (std)\", \"concavity (std)\", \"concave points (std)\", \"symmetry (std)\", \"fractal dimension (std)\", \"radius (largest)\", \"texture (largest)\", \"perimeter (largest)\", \"area (largest)\", \"smoothness (largest)\", \"compactness (largest)\", \"concavity (largest)\", \"concave points (largest)\", \"symmetry (largest)\", \"fractal dimension (largest)\"]] = df[[\"radius (mean)\", \"texture (mean)\", \"perimeter (mean)\", \"area (mean)\", \"smoothness (mean)\", \"compactness (mean)\", \"concavity (mean)\", \"concave points (mean)\", \"symmetry (mean)\", \"fractal dimension (mean)\", \"radius (std)\", \"texture (std)\", \"perimeter (std)\", \"area (std)\", \"smoothness (std)\", \"compactness (std)\", \"concavity (std)\", \"concave points (std)\", \"symmetry (std)\", \"fractal dimension (std)\", \"radius (largest)\", \"texture (largest)\", \"perimeter (largest)\", \"area (largest)\", \"smoothness (largest)\", \"compactness (largest)\", \"concavity (largest)\", \"concave points (largest)\", \"symmetry (largest)\", \"fractal dimension (largest)\"]].apply(pd.to_numeric)\n",
    "df['Diagnosis'] = pd.Categorical(df.Diagnosis)\n",
    "\n",
    "# Calculate summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: Diagnosis, Length: 569, dtype: category\n",
       "Categories (2, object): [B, M]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve features/attributes of dataset\n",
    "X = df.iloc[:,2:31]\n",
    "X\n",
    "\n",
    "y = df.iloc[:,1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write a Python 2/3 compatible codebase, the first step is to add this line to the top of each module\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Import necessary libraries and modules \n",
    "# Matplotlib inline allows the output of plotting commands will be displayed inline\n",
    "%matplotlib inline                      \n",
    "from sklearn import linear_model # The sklearn.linear_model module implements generalized linear models. LR is part of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Load Libraries and Modules #########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "############################################    Split the Data   ############################################\n",
    "\n",
    "# Split validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Train the Logistic Regression Model ####################################\n",
    "\n",
    "# We create an instance of the Classifier\n",
    "# Logistic Regression (aka logit) classifier.\n",
    "clf = linear_model.LogisticRegression(C=1e5) # C parameter is the inverse of regularization strength\n",
    "                                             # C must be a positive float\n",
    "                                             # C in this case is 1/lambda\n",
    "                                             # Smaller values specify stronger regularization\n",
    "                                             # Applies regularization by default; you can set C very large to avoid regularization (setting penalty l2 can speed up the estimations with a very large C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights of the attributes are: [[-3.96003668 -0.01278366  0.84983593 -0.03933345  0.14897801  0.72672312\n",
      "   1.00832831  0.43053192  0.20027552  0.05603655 -0.12377089 -1.80617296\n",
      "   0.11164767  0.12084545  0.02111349  0.14651442  0.21179079  0.0582116\n",
      "   0.07366162  0.0152555  -3.71958725  0.34327156 -0.03990277  0.06763821\n",
      "   0.27206621  2.12134319  2.66912794  0.79084089  0.81034071]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the model (fit the data)\n",
    "# As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, \n",
    "# of size [n_samples, n_features] holding the training samples, and an array Y of integer values, size [n_samples], \n",
    "# holding the class labels for the training samples:\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print('The weights of the attributes are:', clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B [9.99755177e-01 2.44823132e-04] 1.0\n"
     ]
    }
   ],
   "source": [
    "#################################### Apply the Logistic Regression Model ####################################\n",
    "\n",
    "y_pred = clf.predict(X_test)             # Classification prediction\n",
    "y_pred_prob = clf.predict_proba(X_test)  # Class probabilities\n",
    "print(y_pred[0], y_pred_prob[0], np.sum(y_pred_prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138   5]\n",
      " [  6  79]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.97      0.96       143\n",
      "           M       0.94      0.93      0.93        85\n",
      "\n",
      "    accuracy                           0.95       228\n",
      "   macro avg       0.95      0.95      0.95       228\n",
      "weighted avg       0.95      0.95      0.95       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################### Evaluate the Logistic Regression Model ##################################\n",
    "\n",
    "# Build a text report showing the main classification metrics (out-of-sample performance)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1st instance is predicted to belong to class: ['M']\n",
      "The probabilities of belonging to each one of the classes are estimated as: [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#################################### Apply the Logistic Regression Model ####################################\n",
    "\n",
    "# After being fitted, the model can then be used to predict the class of samples:\n",
    "print('The 1st instance is predicted to belong to class:', clf.predict(df.iloc[:1, 2:31]))\n",
    "\n",
    "# Alternatively, the probability of each class can be predicted, which is the fraction of training samples of the same class in a leaf:\n",
    "print('The probabilities of belonging to each one of the classes are estimated as:', clf.predict_proba(df.iloc[:1, 2:31]))\n",
    "\n",
    "# We can also try clf.decision_function(X)\n",
    "# The desion function tells us on which side of the hyperplane generated by the classifier we are \n",
    "# (and how far we are away from it). Based on that information, the estimator then label the examples \n",
    "# with the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the logistic regression boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will help us visualize the decision surfaces\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2= np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Function that will help us visualize the decision surfaces\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "lr = LogisticRegression(C=1e5, random_state=1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_combined, y_combined,\n",
    "                      classifier=lr, test_idx=range(398, 569))\n",
    "\n",
    "plt.xlabel('Attibutes [standardized]')\n",
    "plt.ylabel('Target [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ValueError: X has 2 features per sample; expecting 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Generalization Performance with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Logistic Regression with Cross Validation ####################################\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Fit model to all the data\n",
    "clf_lr = linear_model.LogisticRegression(C=1)\n",
    "\n",
    "# Evaluate performance with cross-validation\n",
    "# Read more about cross_val_score in the following link \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\n",
    "\n",
    "# Accuracy\n",
    "scores=cross_val_score(clf_lr, df.iloc[:, 2:31], df.iloc[:, 1], cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)\n",
    "\n",
    "# F-1 scores\n",
    "scores_f1=cross_val_score(clf_lr, df.iloc[:, 2:31], df.iloc[:, 1], cv=10, scoring='f1_macro')\n",
    "print(\"F1-score: %0.2f (+/- %0.2f)\" % (scores_f1.mean(), scores_f1.std() * 2))# returns an array of scores of the estimator for each run of the cross validation.\n",
    "print(scores_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features of the data\n",
    "scores = cross_val_score(clf_lr, df.iloc[:, 2:31], df.iloc[:, 1], cv=10, scoring='f1_macro')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Define function that plots Learning Curves ##################################\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)): # np.linspace(.1, 1.0, 5) will return evenly\n",
    "                                                                        # spaced 5 numbers from 0.1 to 1.0\n",
    "                        # n_jobs is the number of CPUs to use to do the computation. \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Visualization patamters\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    # Estimate train and test score for different training set sizes\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes) # learning_curve Determines cross-validated \n",
    "                                                                        # training and test scores for different \n",
    "                                                                        # training set sizes.\n",
    "\n",
    "    # Estimate statistics of train and test scores (mean, std)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    # Fill the area around the mean scores with standard deviation info\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\") # Fill for train set scores\n",
    "\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")  # Fill for test set scores\n",
    "    \n",
    "    # Visualization parameters that will allow us to distinguish train set scores from test set scores\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Plot Learning Curves (LR and kNN) #######################################\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "\n",
    "title = \"Learning Curve (LR)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "estimator = LogisticRegression()\n",
    "plot_learning_curve(estimator, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "title = \"Learning Curve (kNN)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "estimator = neighbors.KNeighborsClassifier() #n_neighbors=\n",
    "plot_learning_curve(estimator, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
