
# 🔢 Fundamentals of Numeric Predictions

Covers techniques for predicting continuous variables using regression, k-NN, and decision trees.

## 📌 Key Methods

### Linear Regression
- Fits a linear equation to minimize squared error.
- Can use forward selection, backward elimination, or regularization (Lasso, Ridge).

### k-NN for Regression
- Uses average of k-nearest neighbors.
- Weighted or unweighted depending on distance.

### Regression Trees
- Uses recursive partitioning to split data into homogeneous regions.
- Predicts using the mean of the target in each region.

## 📏 Evaluation Metrics
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- MAPE (Mean Absolute Percentage Error)

---

## ✅ Best Practices
- Use subset selection to avoid overfitting.
- Normalize features for k-NN.
- Prune trees to prevent overly complex models.
